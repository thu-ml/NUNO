from timeit import default_timer
from tqdm import tqdm
from util.utilities3 import *
from torch.optim import Adam
from ..nufno.nufno_2d import NUFNO2d, EncoderDecoder
from .kdtree import KDTree
from sklearn.neighbors import KernelDensity


# Specify a random seed
# Note: reproducibility is not strictly guaranteed across different hardwares.
# We refer to https://pytorch.org/docs/stable/notes/randomness.html
torch.manual_seed(2021)
np.random.seed(2021)
torch.cuda.manual_seed(2021)
torch.backends.cudnn.deterministic = True


################################################################
# Configs
################################################################

# Preprocessing params
# The number of sub-domains which is 
# generated by KD-Tree splitting algorithm
n_subdomains = 8
# Oversampling ratio for interpolation when preprocessing
oversamp_r_pre = 8
# Oversampling ratio for interpolation when training
oversamp_r_train = 2
# The bandwidth of the kernel of the density estimator
bandwidth = 0.05

# Data size
Ntotal = 2000
ntrain = 1000
ntest = 200
# Data paths
PATH = 'data/elasticity/'
PATH_SIGMA = PATH + 'Random_UnitCell_sigma_10.npy'
PATH_XY = PATH + 'Random_UnitCell_XY_10.npy'
PATH_RR = PATH + 'Random_UnitCell_rr_10.npy'
PATH_IND = PATH + 'Preprocess_ind.npy'
PATH_SEP = PATH + 'Preprocess_sep.npy'
PATH_SD_INFO = PATH + 'Preprocess_subdomain_info.npy'
PATH_DMODES_1 = PATH + 'Preprocess_density_modes_1.npy'
PATH_DMODES_2 = PATH + 'Preprocess_density_modes_2.npy'

# Training params
batch_size = 20
learning_rate = 0.001
epochs = 501
# Step LR scheduler
step_size = 50
gamma = 0.5

# Network params
modes1 = modes2 = 16  # truncated Fourier modes (ky_max, kx_max)
width = 32            # hidden width


################################################################
# Data loading and preprocessing (via KD-Tree)
################################################################
# Wether to save or load preprocessing results
SAVE_PREP = True
LOAD_PREP = False

# Load data
input_rr = np.load(PATH_RR)
input_rr = np.transpose(input_rr, (1, 0))
input_sigma = np.load(PATH_SIGMA)
input_sigma = np.transpose(input_sigma, (1, 0))
input_xy = np.load(PATH_XY)
input_xy = np.transpose(input_xy, (2, 0, 1))
input_xy = np.concatenate(
    (input_xy[:ntrain], input_xy[-ntest:]), 
    axis=0
)

if LOAD_PREP:
    input_ind = np.load(PATH_IND)
    input_sep = np.load(PATH_SEP)
    input_sd_info = np.load(PATH_SD_INFO)
    input_dmodes_1 = np.load(PATH_DMODES_1)
    input_dmodes_2 = np.load(PATH_DMODES_2)
else:
    print("Start KD-Tree splitting...")
    input_ind = []
    input_sep = []
    input_sd_info = []
    t1 = default_timer()
    for i in tqdm(range(len(input_xy)), leave=False):
        point_cloud = input_xy[i].tolist()  # N_points x 2
        tree= KDTree(
            point_cloud, dim=2, n_subdomains=n_subdomains, 
            n_blocks=8, return_indices=True
        )
        # The index (of each point contained in the subdomains) 
        # in the original sequence `point_cloud`
        subdomain_indices = tree.get_subdomain_indices()
        # The length of `input_ind` is equal to N_points
        input_ind.append(np.concatenate(subdomain_indices))
        # Record the border of the sequence corresponding to 
        # the indices of each subdomain
        # Note: this vector is used to restore `subdomain_indices`
        # from `input_ind`
        subdomain_separator = [0] * (n_subdomains + 1)
        for j in range(n_subdomains):
            subdomain_separator[j+1] = subdomain_separator[j] + \
                subdomain_indices[j].shape[0]
        input_sep.append(subdomain_separator)

        # Gather subdomain info:
        # (xmin, ymin, xlen, ylen, grid_size_x, grid_size_y)
        bboxes = tree.get_subdomain_bounding_boxes()
        info = []
        for j in range(n_subdomains):
            bbox = bboxes[j]
            n_points = subdomain_indices[j].shape[0]
            # Calculate the grid size used for interpolation when training, 
            # where the length-to-width ratio of the discrete grid 
            # remains the same as the that of the original subdomain ('s bounding box)
            grid_size_x = np.sqrt(n_points * oversamp_r_train * \
                (bbox[0][1] - bbox[0][0]) / (bbox[1][1] - bbox[1][0]))
            grid_size_y = grid_size_x * (bbox[1][1] - bbox[1][0]) / (bbox[0][1] - bbox[0][0])
            grid_size_x, grid_size_y = max(int(np.round(grid_size_x)), 2), max(int(np.round(grid_size_y)), 2)
            # subdomain info: (xmin, ymin, xlen, ylen, grid_size_x, grid_size_y)
            info.append((bbox[0][0], bbox[1][0], bbox[0][1] - bbox[0][0], bbox[1][1] - bbox[1][0],
                grid_size_x, grid_size_y))
        input_sd_info.append(info)
    t2 = default_timer()
    input_ind = np.array(input_ind)
    input_sep = np.array(input_sep)
    input_sd_info = np.array(input_sd_info)
    print("Finish KD-Tree splitting, time elapsed: {:.1f}s".format(t2-t1))

    # Estimate the density distribution (probability) of the point cloud, 
    # which serves as the input of the neural operator.
    # Then compute the Fourier modes of the density function
    print("Start estimating the density distribution of point clouds...")
    # Since the result of real FFT is Hermitian,
    # we can simply store half of it (which are represented as two parts)
    input_dmodes_1 = []
    input_dmodes_2 = []
    t1 = default_timer()
    for i in tqdm(range(len(input_xy)), leave=False):
        kde = KernelDensity(kernel='gaussian', bandwidth=bandwidth).fit(input_xy[i])
        input_dmodes_1.append([])
        input_dmodes_2.append([])
        # Evaluate on each subdomain (uniform grid)
        for j in range(n_subdomains):
            n_points = input_sep[i, j+1] - input_sep[i, j]
            xmin, ymin, xlen, ylen = input_sd_info[i, j, :4]
            # Calculate the grid size used for interpolation when preprocessing, 
            # where the length-to-width ratio of the discrete grid 
            # remains the same as the that of the original subdomain ('s bounding box)
            grid_size_x = np.sqrt(n_points * oversamp_r_pre * xlen / ylen)
            grid_size_y = grid_size_x * ylen / xlen
            grid_size_x, grid_size_y = max(int(np.round(grid_size_x)), 2 * (modes2 - 1)), \
                max(int(np.round(grid_size_y)), 2 * (modes1 - 1))
            # Generate the uniform gird
            grid_x = np.linspace(xmin, xmin + xlen, num=grid_size_x)
            grid_y = np.linspace(ymin, ymin + ylen, num=grid_size_y)
            grid_x, grid_y = np.meshgrid(grid_x, grid_y)
            # Grid size: grid_size_y x grid_size_x x 2
            # Note: the indexing mode is 'xy' (see np.meshgrid docs for more info)
            grid = np.stack((grid_x, grid_y), axis=-1)
            positions = grid.reshape(-1, 2)
            # Evaluating of KernelDensity
            density_prob = np.exp(kde.score_samples(positions)).reshape(grid.shape[0], grid.shape[1])
            # Computing Fourier modes normalized by 1/n
            # to facilitate the combination of subdomain modes to form overall domain modes
            modes = np.fft.rfft2(density_prob, norm='forward')
            input_dmodes_1[i].append(modes[:modes1, :modes2])
            input_dmodes_2[i].append(modes[-modes1:, :modes2])
    
    t2 = default_timer()
    input_dmodes_1 = np.array(input_dmodes_1)
    input_dmodes_2 = np.array(input_dmodes_2)
    print("Finish estimating the density distribution of point clouds, time elapsed: {:.1f}s".format(t2-t1))

    if SAVE_PREP:
        np.save(PATH_IND, input_ind)
        np.save(PATH_SEP, input_sep)
        np.save(PATH_SD_INFO, input_sd_info)
        np.save(PATH_DMODES_1, input_dmodes_1)
        np.save(PATH_DMODES_2, input_dmodes_2)

################################################################
# Preparing the dataset
################################################################
input_rr = torch.tensor(input_rr, dtype=torch.float)
input_xy = torch.tensor(input_xy, dtype=torch.float)
input_sigma = torch.tensor(input_sigma, dtype=torch.float).unsqueeze(-1)
input_ind = torch.tensor(input_ind, dtype=torch.long)
input_sep = torch.tensor(input_sep, dtype=torch.long)
input_sd_info = torch.tensor(input_sd_info)
input_dmodes_1 = torch.tensor(input_dmodes_1, dtype=torch.cfloat)
input_dmodes_2 = torch.tensor(input_dmodes_2, dtype=torch.cfloat)

train_rr = input_rr[:ntrain]
test_rr = input_rr[-ntest:]
train_xy = input_xy[:ntrain]
test_xy = input_xy[-ntest:]
train_sigma = input_sigma[:ntrain]
test_sigma = input_sigma[-ntest:]
train_ind = input_ind[:ntrain]
test_ind = input_ind[-ntest:]
train_sep = input_sep[:ntrain]
test_sep = input_sep[-ntest:]
train_sd_info = input_sd_info[:ntrain]
test_sd_info = input_sd_info[-ntest:]
train_dmodes_1 = input_dmodes_1[:ntrain]
test_dmodes_1 = input_dmodes_1[-ntest:]
train_dmodes_2 = input_dmodes_2[:ntrain]
test_dmodes_2 = input_dmodes_2[-ntest:]

train_loader = torch.utils.data.DataLoader(
    torch.utils.data.TensorDataset(
        train_rr, train_xy, train_sigma, 
        train_ind, train_sep, train_sd_info,
        train_dmodes_1, train_dmodes_2
    ), 
    batch_size=batch_size, shuffle=True,
    generator=torch.Generator(device=device)
)
test_loader = torch.utils.data.DataLoader(
    torch.utils.data.TensorDataset(
        test_rr, test_xy, test_sigma,
        test_ind, test_sep, test_sd_info,
        test_dmodes_1, test_dmodes_2
    ), 
    batch_size=batch_size, shuffle=False,
    generator=torch.Generator(device=device)
)

################################################################
# Training and evaluation
################################################################
model = NUFNO2d(modes, modes, width, in_channels=2, out_channels=1, n_subdomains=n_subdomains)
model_encoder = EncoderDecoder()
print("Model size: %d"%(count_params(model) + count_params(model_encoder)))

params = list(model.parameters()) + list(model_encoder.parameters())
optimizer = Adam(params, lr=learning_rate, weight_decay=1e-4)
scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=gamma)

myloss = LpLoss(size_average=False)
for ep in range(epochs):
    model.train()
    t1 = default_timer()
    train_l2 = 0.0
    for rr, xy, sigma, ind, sep, s_info in train_loader:
        optimizer.zero_grad()
        out = model(xy, ind, sep, s_info, code=rr, encoder=model_encoder)

        loss = myloss(out.view(batch_size, -1), sigma.view(batch_size, -1))
        loss.backward()
        optimizer.step()
        train_l2 += loss.item()

    scheduler.step()

    model.eval()
    test_l2 = 0.0
    with torch.no_grad():
        for rr, xy, sigma, ind, sep, s_info in test_loader:
            out = model(xy, ind, sep, s_info, code=rr, encoder=model_encoder)
            test_l2 += myloss(out.view(batch_size, -1), sigma.view(batch_size, -1)).item()

    train_l2 /= ntrain
    test_l2 /= ntest

    t2 = default_timer()
    print("[Epoch {}] Time: {:.1f}s L2: {:>4e} Test_L2: {:>4e}"
            .format(ep, t2-t1, train_l2, test_l2))

    if ep%100==0:
        pass
        # XY = loc[-1].squeeze().detach().cpu().numpy()
        # truth = sigma[-1].squeeze().detach().cpu().numpy()
        # pred = out[-1].squeeze().detach().cpu().numpy()

        # lims = dict(cmap='RdBu_r', vmin=truth.min(), vmax=truth.max())
        # fig, ax = plt.subplots(nrows=1, ncols=3, figsize=(12, 4))
        # ax[0].scatter(XY[:, 0], XY[:, 1], 100, truth, edgecolor='w', lw=0.1, **lims)
        # ax[1].scatter(XY[:, 0], XY[:, 1], 100, pred, edgecolor='w', lw=0.1, **lims)
        # ax[2].scatter(XY[:, 0], XY[:, 1], 100, truth - pred, edgecolor='w', lw=0.1, **lims)
        # fig.show()